# -*- coding: utf-8 -*-
"""production_pipeline.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1EvZjhSOxTX7UcBW9-moLsmwHEtJ0bWJ0


# Imports
"""

import os
import requests
import pandas as pd
from PIL import Image
from io import BytesIO
from requests.adapters import HTTPAdapter
from requests.packages.urllib3.util.retry import Retry
from tqdm import tqdm  # Progress bar

# For loading in dataset images and annotations
import json
import sys

from etils import epath
import numpy as np
import tensorflow_datasets.public_api as tfds

# Displaying sample images
import itertools

import tarfile
import glob
import re
import matplotlib.pyplot as plt
import matplotlib.image as mpimg


import matplotlib.pyplot as plt
import numpy as np
import pathlib

# python imaging library
# adds image processing capabilities to the interpreter
import PIL
import tensorflow as tf

from tensorflow import keras
from tensorflow.keras import layers, models
from tensorflow.keras.models import Sequential
from tensorflow.keras.applications import ResNet50
from tensorflow.keras.layers.experimental import preprocessing

from latin_to_colloquial import AnimalPipeline

if __name__ == "__main__":
    """# Gathering species and number of images per species"""

    species_names = []
    numAnimals = int(input("Enter the number of animals you want to train: \n"))
    for i in range(numAnimals):
        species_names.append(input("Enter the name of the animal: \n"))

    max_images_per_species = int(input("Enter the maximum number of images you want to download for each animal: \n"))

    file_path = "./data/animal_latin_colloquial.csv"

    pipeline = AnimalPipeline(file_path)

    for name in species_names.copy():
        if pipeline.animal_exists(name) == False:
            if pipeline.check_latin_name(name) == False:
                print(f"{name} does not exist in the dataset. Please enter a valid animal name.")
                species_names.remove(name)
                continue
        latin_name = pipeline.get_latin_name(name)
        species_names.remove(name)
        species_names.append(latin_name)

    IMG_HEIGHT = 180; IMG_WIDTH = 180   # size of image has to 180x180 since ResNet50 is used

    """# Loading inaturalist images for training split via iNaturalist API"""

    # Function to download and resize image
    def download_and_resize_image(url, save_dir, obs_id, max_size=(IMG_HEIGHT, IMG_WIDTH)):
        try:
            response = requests.get(url, timeout=10)
            response.raise_for_status()
            img = Image.open(BytesIO(response.content))
            img = img.resize(max_size, resample = Image.Resampling.BICUBIC)

            # Ensure the save directory exists
            os.makedirs(save_dir, exist_ok=True)

            # Save the image with a unique name based on the observation ID
            img_name = f"{obs_id}.jpg"
            img_path = os.path.join(save_dir, img_name)
            img.save(img_path)
            return img_path
        except Exception as e:
            return None

    session = requests.Session()
    retry_strategy = Retry(
        total=3,
        status_forcelist=[429, 500, 502, 503, 504],
        backoff_factor=1
    )
    adapter = HTTPAdapter(max_retries=retry_strategy)
    session.mount('https://', adapter)

    for species_name in species_names:
        try:
            # Directory to save images for the current species, change as needed
            save_dir = f'./dataset/{species_name.replace(" ", "_")}_images'

            # Fetch taxon ID for the current species name
            search_response = session.get(f'https://api.inaturalist.org/v1/taxa?q={species_name}&rank=species', timeout=10).json()
            if not search_response['results']:
                print(f"No taxon found for species: {species_name}")
                continue

            # Assume the first result is the desired species
            taxon_id = search_response['results'][0]['id']

            observation_ids = []
            image_urls = []
            common_names = []
            scientific_names = []

            valid_image_count = 0

            # Fetch observations for the current species until the desired number of images is reached
            page = 1
            while valid_image_count < max_images_per_species:
                observations_response = session.get(
                    f'https://api.inaturalist.org/v1/observations?taxon_id={taxon_id}&per_page=200&page={page}', timeout=10
                ).json()
                observations = observations_response['results']

                if not observations:
                    break

                for observation in tqdm(observations, desc=f'Processing observations for {species_name}'):
                    if valid_image_count >= max_images_per_species:
                        break

                    # Extract and store observation details
                    obs_id = observation['id']
                    taxon = observation.get('taxon')
                    if taxon:
                        common_name = taxon.get('preferred_common_name', 'No common name available')
                        scientific_name = taxon.get('name', 'No scientific name available')
                    else:
                        common_name = 'No common name available'
                        scientific_name = 'No scientific name available'

                    # Extract and store image data
                    if 'observation_photos' in observation and observation['observation_photos']:
                        photo = observation['observation_photos'][0]['photo']
                        image_url = photo['url']
                        image_path = download_and_resize_image(image_url, save_dir=save_dir, obs_id=obs_id, max_size = (IMG_HEIGHT, IMG_WIDTH))
                        if image_path:
                            observation_ids.append(obs_id)
                            common_names.append(common_name)
                            scientific_names.append(scientific_name)
                            image_urls.append(image_url)
                            valid_image_count += 1

                page += 1

            # Create a DataFrame with observation details for the current species
            data = {
                'Observation ID': observation_ids,
                'Common Name': common_names,
                'Scientific Name': scientific_names,
                'Image URL': image_urls,
                'Image Path': [os.path.join(save_dir, f"{obs_id}.jpg") for obs_id in observation_ids]
            }
            df = pd.DataFrame(data)

            # Cap the dataset size to match the number of images available
            if valid_image_count < max_images_per_species:
                df = df.head(valid_image_count)

            # Save to a CSV file for the current species, change as needed
            csv_path = f'./dataset/{species_name.replace(" ", "_")}_dataset.csv'
            df.to_csv(csv_path, index=False)

            print(f"Data saved to {csv_path} for species: {species_name}")

        except requests.exceptions.HTTPError as e:
            print(f"HTTP error occurred: {e}")

    # Count number of images downloaded
    path = './dataset'
    folders = os.listdir(path)
    totalImages = 0
    for folder in folders:
      images = os.listdir(f"{path}/{folder}")
      totalImages += len(images)

    print(totalImages)

    """# Loading inaturalist images for validation split via inat competition 2021

    ## Setup
    """

    dm = tfds.download.DownloadManager(download_dir='./dataset')

    URL = 'https://ml-inat-competition-datasets.s3.amazonaws.com/2021'    # endpoint to load images from

    # maps split type to split file name
    SPLIT_FILENAMES = {
        'train': 'train',
        'mini': 'train_mini',
        'val': 'val',
        'test': 'public_test',
    }

    # Only load validation set
    SPLIT = 'val'
    SPLIT_FILE = SPLIT_FILENAMES[SPLIT]

    # maps dataset to split tar & json files
    splitDownloads = {}

    """## Download"""

    # download image tar file
    splitDownloads[f'{SPLIT}_img'] =  tfds.download.Resource(
              url=f'{URL}/{SPLIT_FILE}.tar.gz',
              extract_method=tfds.download.ExtractMethod.NO_EXTRACT,
          )
    # download json annotation file
    splitDownloads[f'{SPLIT}_json'] = f'{URL}/{SPLIT_FILE}.json.tar.gz'

    print(splitDownloads)

    outputPaths = dm.download_and_extract(splitDownloads)     # downloading the tar file containing validation images

    """## Retrieving annotations from JSON file to load images from validation dataset

    """

    # paths to loaded dataset

    imagesArchive = outputPaths[f'{SPLIT}_img']
    jsonFile = os.path.join(outputPaths[f'{SPLIT}_json'],f'{SPLIT_FILE}.json')

    with epath.Path(jsonFile).open('r') as f:
          inatJson = json.load(f)

    def format(label: str):
          # replace ' ' with '_' in a string
          return label.lower().replace(' ', '_')

    # retrieves annotations (categories, id and image directory) for an image
    def getAnnotation(idx, image_id):

          if 'annotations' in inatJson:

            # get the annotations object that matches our ID
            annotation = inatJson['annotations'][idx]
            assert annotation['image_id'] == image_id

            # retrieve 'categories' object corresponding to the id in the annotation object
            cat = inatJson['categories'][annotation['category_id']]

            # extract important metadata
            category = format(cat['name'])
            superCategory = format(cat['supercategory'])
            imageDirectory = cat['image_dir_name']

          else:
            # no metadata found
            category, superCategory, imageDirectory = -1, -1, -1

          return category, superCategory, imageDirectory

    """## Curating collection of annotated images

    ###Filtering

    The code below allows us ensure that we only extract images related to vertebrates and our 5 selected species.
    """

    # List containing the vertebrates recognised by iNaturalist Dataset
    vertebrates = ["jawless_fishes", "hagfishes", "lampreys", "ray-finned_fishes", "amphibians", "birds", "elasmobranchs", "chimaeras", "mammals", "reptiles", "lobe-finned_fishes"]

    # List containing the animals that user want to see/train on
    animalsToRetrieve = [format(name).lower() for name in species_names]      # formated so that images can be recognised
    print(animalsToRetrieve)

    """###Map images to their annotations"""

    annotatedFiles = {}   # stores specified annotation and metadata of species

    for idx, image in enumerate(inatJson['images']):

      category, superCategory, imageDirectory = getAnnotation(idx, image['id'])
      if (superCategory in vertebrates) and (category in animalsToRetrieve):      # Checking if the species is a vertebrate and checking latin name of the animal (using category)
        field = os.path.basename(image['file_name']).split('.')[0]

        annotatedFiles[field] = {
            'id': image['id'],
            'file_id': field,
            'label': category,      # latin name
            'superCategory': superCategory,
            'imagedirectory' : imageDirectory,
        }

    print(annotatedFiles)
    print(len(annotatedFiles))

    """## Extracting the images"""

    # image file paths in tar.gz file
    imgToExtract = []

    try:
      t = tarfile.open(imagesArchive, 'r')

    except IOError as e:
      print(e)

    else:

      for id,value in annotatedFiles.items():

        # create image file path
        imgFilePath = f"val/{value['imagedirectory']}/{id}.jpg"         # specfying the file path to store the extracted images
        imgToExtract.append(imgFilePath)

      t.extractall('./dataset', members=imgToExtract)

    """## Resizing and renaming"""

    # rename all folders to match class names of the training dataset
    path = './dataset/val'
    dirs = os.listdir(path)

    for folder in dirs:
      # rename species folder
      os.rename(f"{path}/{folder}", f"{path}/{'_'.join(folder.split('_')[6::])}_images")

      # get path of each image in class folder
      new_path = f"{path}/{'_'.join(folder.split('_')[6::])}_images"
      image_dir = os.listdir(new_path)

      for item in image_dir:
        item_path = f"{new_path}/{item}"

        if os.path.isfile(item_path):
          im = Image.open(item_path)
          f, e = os.path.splitext(item_path)
          imResize = im.resize((IMG_HEIGHT, IMG_WIDTH))     # resizing image so that it can be read by the model
          imResize.save(item_path,'JPEG', quality=90)

    """# Building the Model

    ## Preprocessing / Creating dataset
    """

    BATCH_SIZE = 32
    data_dir = pathlib.Path('./dataset').with_suffix('')  # Directory storing the training data

    # Quick check on the dataset
    image_count = len(list(data_dir.glob('*/*.jpg')))
    print(f"Found {image_count} images.")

    # Creating the training dataset
    train_ds = tf.keras.utils.image_dataset_from_directory(
        data_dir,
        validation_split=None,
        subset=None,
        seed=123,
        image_size=(IMG_HEIGHT, IMG_WIDTH),
        batch_size=BATCH_SIZE
    )

    # Identifying class names
    class_names = train_ds.class_names
    print(class_names)

    # Print a batch shape
    for image_batch, labels_batch in train_ds:
        print(image_batch.shape)
        print(labels_batch.shape)
        break

    # Creating the validation dataset
    val_ds = tf.keras.utils.image_dataset_from_directory(
        '/dataset/val',
        validation_split=None,
        subset=None,
        seed=123,
        image_size=(IMG_HEIGHT, IMG_WIDTH),
        batch_size=BATCH_SIZE
    )

    # Configuring dataset for performance
    AUTOTUNE = tf.data.AUTOTUNE
    train_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)
    val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)

    # Number of classes
    NUM_CLASSES = len(class_names)

    """## Creating, compiling and training the model"""

    resnet_model = ResNet50(weights='imagenet', include_top=False, input_shape=(IMG_HEIGHT, IMG_WIDTH, 3))

    # Freeze the pretrained weights
    resnet_model.trainable = False

    # Create a new model on top
    inputs = keras.Input(shape=(IMG_HEIGHT, IMG_WIDTH, 3))
    x = resnet_model(inputs, training=False)
    x = layers.GlobalAveragePooling2D()(x)
    outputs = layers.Dense(NUM_CLASSES)(x)
    model = keras.Model(inputs, outputs)


    # Compile the model
    model.compile(optimizer='adam',
                  loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
                  metrics=['accuracy'])


    # using 10 epochs of size 32 and with model.fit method
    epochs=10
    history = model.fit(
      train_ds,
      validation_data=val_ds,
      epochs=epochs
    )

    """## Visualising model results"""

    acc = history.history['accuracy']
    val_acc = history.history['val_accuracy']

    loss = history.history['loss']
    val_loss = history.history['val_loss']

    epochs_range = range(epochs)

    plt.figure(figsize=(8, 8))
    plt.subplot(1, 2, 1)
    plt.plot(epochs_range, acc, label='Training Accuracy')
    plt.plot(epochs_range, val_acc, label='Validation Accuracy')
    plt.legend(loc='lower right')
    plt.title('Training and Validation Accuracy')

    plt.subplot(1, 2, 2)
    plt.plot(epochs_range, loss, label='Training Loss')
    plt.plot(epochs_range, val_loss, label='Validation Loss')
    plt.legend(loc='upper right')
    plt.title('Training and Validation Loss')
    plt.show()